{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./new-env/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in ./new-env/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./new-env/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: openpyxl in ./new-env/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./new-env/lib/python3.11/site-packages (from pandas) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./new-env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./new-env/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./new-env/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./new-env/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./new-env/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./new-env/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./new-env/lib/python3.11/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./new-env/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: et-xmlfile in ./new-env/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in ./new-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas requests beautifulsoup4 openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch from URL 381 to 390\n",
      "processing URL 381/4913: https://www.channelnewsasia.com/brandstudio/takingon2030/manufacturing\n",
      "extraction successful for this URL\n",
      "processing URL 382/4913: https://www.spgroup.com.sg/about-us/media-resources/news-and-media-releases/SP-Group-to-green-electricity-substations-for-a-more-sustainable-future\n",
      "extraction successful for this URL\n",
      "processing URL 383/4913: https://www.mof.gov.sg/news-publications/speeches/singapore-energy-lecture-by-deputy-prime-minister-and-minister-for-finance-lawrence-wong-at-the-singapore-international-energy-week-on-25th-october-2022\n",
      "extraction successful for this URL\n",
      "processing URL 384/4913: https://www.aboutamazon.sg/news/aws/aws-and-imda-launch-first-of-its-kind-joint-innovation-centre-in-southeast-asia-to-deepen-collaboration-and-industry-innovation\n",
      "extraction successful for this URL\n",
      "processing URL 385/4913: https://www.medlabasia.com/asiahealth/en/newsroom.html\n",
      "extraction successful for this URL\n",
      "processing URL 386/4913: https://clustercollaboration.eu/events/organised-by-eccp/matchmaking/singapore\n",
      "extraction successful for this URL\n",
      "processing URL 387/4913: https://www1.bca.gov.sg/buildsg/sustainability/green-mark-incentive-schemes/green-mark-incentive-scheme-for-existing-buildings-2.0\n",
      "extraction successful for this URL\n",
      "processing URL 388/4913: https://www.moomoo.com/sg/learn/detail-what-are-reits-reits-in-singapore-85551-221103153\n",
      "extraction successful for this URL\n",
      "processing URL 389/4913: https://www.lhngroup.com/tag/the-edge-singapore/\n",
      "extraction successful for this URL\n",
      "processing URL 390/4913: https://www.99.co/singapore/insider/singapore-estates-future-property-investment/\n",
      "extraction successful for this URL\n",
      "batch from URL 381 to 390 saved.\n",
      "processing batch from URL 391 to 400\n",
      "processing URL 391/4913: https://www.teckwahgroup.com/\n",
      "extraction successful for this URL\n",
      "processing URL 392/4913: https://www.property-forum.eu/news/slovak-industrial-market-slows-down-in-q3-2022/14058\n",
      "extraction successful for this URL\n",
      "processing URL 393/4913: https://www.eastspring.com/lu/insights/outlook/charting-sustainability-pathways\n",
      "extraction successful for this URL\n",
      "processing URL 394/4913: https://www.propertyguru.com.sg/property-guides/land-betterment-charge-singapore-74962\n",
      "extraction successful for this URL\n",
      "processing URL 395/4913: https://customs.gov.sg/businesses/border-enforcement-of-intellectual-property-rights/quick-guide-for-copyright-and-trade-mark-owners-and-licensees/\n",
      "extraction successful for this URL\n",
      "processing URL 396/4913: https://www.marketscreener.com/stock-exchange/shares/asia/singapore-141/\n",
      "extraction successful for this URL\n",
      "processing URL 397/4913: https://www.poems.com.sg/market-journal/are-singapore-reits-still-a-good-buy/\n",
      "extraction successful for this URL\n",
      "processing URL 398/4913: https://www.arcweb.com/market-analysis/industrial-cybersecurity-market-analysis-research\n",
      "extraction successful for this URL\n",
      "processing URL 399/4913: https://content.mycareersfuture.gov.sg/ict-sector-jobs-salaries-career-conversion-programmes/\n",
      "extraction successful for this URL\n",
      "processing URL 400/4913: https://aais.org.sg/itm2025preview/\n",
      "extraction successful for this URL\n",
      "batch from URL 391 to 400 saved.\n",
      "processing batch from URL 401 to 410\n",
      "processing URL 401/4913: https://www.facebook.com/uob.sg/videos/eric-lim-singapore-fintech-festival-2022/868998387887001/\n",
      "extraction successful for this URL\n",
      "processing URL 402/4913: https://www2.staffingindustry.com/row/Editorial/Daily-News/Singapore-Online-recruitment-rises-3-in-August-growth-led-by-education-sector-63332\n",
      "extraction successful for this URL\n",
      "processing URL 403/4913: https://estates.jtc.gov.sg/jid/stories/acceclerating-the-adoption-of-advanced-manufacturing\n",
      "extraction successful for this URL\n",
      "processing URL 404/4913: https://www.sgx.com/research-education/market-updates/20220627-singapore-listed-manufacturing-stocks-move#:~:text=Singapore's%20Industrial%20Production%20has%20booked,18%20months%20on%20YoY%20basis.\n",
      "extraction successful for this URL\n",
      "processing URL 405/4913: https://www.edgeprop.sg/property-news/industrial-rents-increased-sixth-straight-quarter-1q2022\n",
      "extraction successful for this URL\n",
      "processing URL 406/4913: https://www.retalkasia.com/news/2022/04/29/singapore-industrial-rent-and-prices-continue-soar-1q22-says-jll%C2%A0/1651183652\n",
      "extraction successful for this URL\n",
      "processing URL 407/4913: https://www.cushmanwakefield.com/en/singapore/news/2022/04/prime-logistics-properties-continues-to-outperform\n",
      "extraction successful for this URL\n",
      "processing URL 408/4913: https://www.edgeprop.sg/property-news/industrial-sales-and-leasing-activities-rise-49-y-o-y-1q-knight-frank\n",
      "extraction successful for this URL\n",
      "processing URL 409/4913: https://www.statista.com/outlook/cmo/diy-hardware-store/tools-machines/singapore\n",
      "extraction successful for this URL\n",
      "processing URL 410/4913: https://www.retalkasia.com/news/2022/05/27/singapore-industrial-rents-continue-trending-upwards-says-savills%C2%A0/1653623174\n",
      "extraction successful for this URL\n",
      "batch from URL 401 to 410 saved.\n",
      "processing batch from URL 411 to 420\n",
      "processing URL 411/4913: https://www.jtc.gov.sg/about-jtc/news-and-stories/feature-stories/the-manufacturing-talent-crunch-3-ways-jtc-is-helping-businesses-win-talent\n",
      "extraction successful for this URL\n",
      "processing URL 412/4913: https://omy.sg/business/\n",
      "extraction successful for this URL\n",
      "processing URL 413/4913: https://www.cushmanwakefield.com/en/singapore/offices/singapore\n",
      "extraction successful for this URL\n",
      "processing URL 414/4913: https://www.straitstimes.com/business/economy/growth-in-singapore-factory-output-slows-to-34-in-march-as-pharma-production-falls\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m     text \u001b[38;5;241m=\u001b[39m extract_text(url)\n\u001b[1;32m     45\u001b[0m     batch_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracted Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[0;32m---> 46\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# sleep for 2 seconds between requests\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextraction successful for this URL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# convert batch data to DataFrame and append to the Excel file\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "\n",
    "# load the Excel file with URLs\n",
    "df = pd.read_excel('web_scraping_urls.xlsx')\n",
    "\n",
    "# function to clean text\n",
    "def clean_text(text):\n",
    "    # regex to match non-printable characters\n",
    "    clean_text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
    "    return clean_text\n",
    "\n",
    "# function to extract and clean text from a URL\n",
    "def extract_text(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        # clean the text before returning\n",
    "        return clean_text(text)\n",
    "    except requests.RequestException as e:\n",
    "        return str(e)\n",
    "\n",
    "# define batch size and output file name\n",
    "batch_size = 10\n",
    "output_filename = 'all_extracted_texts.xlsx'\n",
    "\n",
    "# initialize the ExcelWriter to append without overwriting previous data\n",
    "with pd.ExcelWriter(output_filename, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "    total_urls = len(df['URLs'])\n",
    "\n",
    "    # process each batch\n",
    "    for start in range(380, total_urls, batch_size):\n",
    "        end = start + batch_size\n",
    "        print(f\"processing batch from URL {start+1} to {min(end, total_urls)}\")\n",
    "        batch_data = {'URL': df['URLs'][start:end], 'Quarter': df['Quarter'][start:end], 'Extracted Text': []}\n",
    "\n",
    "        for index, url in enumerate(df['URLs'][start:end], start=start+1):\n",
    "            print(f\"processing URL {index}/{total_urls}: {url}\")\n",
    "            text = extract_text(url)\n",
    "            batch_data['Extracted Text'].append(text)\n",
    "            time.sleep(2)  # sleep for 2 seconds between requests\n",
    "            print(\"extraction successful for this URL\")\n",
    "\n",
    "        # convert batch data to DataFrame and append to the Excel file\n",
    "        batch_df = pd.DataFrame(batch_data)\n",
    "        # append batch data to the Excel file\n",
    "        batch_df.to_excel(writer, sheet_name='Extracted Text', index=False, header=not writer.sheets, startrow=writer.sheets['Extracted Text'].max_row if 'Extracted Text' in writer.sheets else 0)\n",
    "\n",
    "        print(f\"batch from URL {start+1} to {min(end, total_urls)} saved.\")\n",
    "\n",
    "print(\"all URLs processed and saved to the same Excel file.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
