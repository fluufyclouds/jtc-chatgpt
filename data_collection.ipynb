{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./new-env/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./new-env/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: fake_useragent in ./new-env/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: pandas in ./new-env/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: openpyxl in ./new-env/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy in ./new-env/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./new-env/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./new-env/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./new-env/lib/python3.11/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./new-env/lib/python3.11/site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./new-env/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./new-env/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./new-env/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./new-env/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: et-xmlfile in ./new-env/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in ./new-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 fake_useragent pandas openpyxl numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "import urllib.parse\n",
    "import time\n",
    "\n",
    "def google_search(query, num_results, time_filter = None):\n",
    "    # initialize UserAgent\n",
    "    ua = UserAgent()\n",
    "    # generate a random user agent for each request\n",
    "    headers = {'User-Agent': ua.random}\n",
    "\n",
    "    # URL encode the query\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "\n",
    "    # construct the Google search URL\n",
    "    google_url = f\"https://www.google.com/search?q={query}&num={num_results}\"\n",
    "\n",
    "    # append the time filter if specified\n",
    "    if time_filter:\n",
    "        google_url += f\"&tbs={time_filter}\"\n",
    "\n",
    "    attempts = 0\n",
    "    while attempts < 5:\n",
    "        # send the request\n",
    "        response = requests.get(google_url, headers=headers)\n",
    "        attempts += 1\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            search_results = []\n",
    "\n",
    "            # extract search result URLs\n",
    "            for g in soup.find_all('div', class_='g'):\n",
    "                anchors = g.find_all('a')\n",
    "                if anchors:\n",
    "                    link = anchors[0]['href']\n",
    "                    search_results.append(link)\n",
    "                \n",
    "            return search_results\n",
    "\n",
    "        elif response.status_code == 429:\n",
    "            print(\"rate limit reached, waiting to retry...\")\n",
    "            time.sleep(10 * attempts)  # exponential back-off\n",
    "\n",
    "        else:\n",
    "            print(f\"failed to retrieve search results: status code {response.status_code}\")\n",
    "            return []\n",
    "        \n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quarters(start_year, end_year):\n",
    "    quarters = {}\n",
    "    if end_year == 2024:\n",
    "        quarters[\"2024 Q1\"] = \"cdr:1,cd_min:1/1/2024,cd_max:3/31/2024\"\n",
    "        quarters[\"2024 Q2\"] = \"cdr:1,cd_min:4/1/2024,cd_max:6/30/2024\"\n",
    "        end_year -= 1\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        quarters[f\"{year} Q1\"] = f\"cdr:1,cd_min:1/1/{year},cd_max:3/31/{year}\"\n",
    "        quarters[f\"{year} Q2\"] = f\"cdr:1,cd_min:4/1/{year},cd_max:6/30/{year}\"\n",
    "        quarters[f\"{year} Q3\"] = f\"cdr:1,cd_min:7/1/{year},cd_max:9/30/{year}\"\n",
    "        quarters[f\"{year} Q4\"] = f\"cdr:1,cd_min:10/1/{year},cd_max:12/31/{year}\"\n",
    "    return quarters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2020 - 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rate limit reached, waiting to retry...\n",
      "rate limit reached, waiting to retry...\n",
      "rate limit reached, waiting to retry...\n",
      "rate limit reached, waiting to retry...\n",
      "rate limit reached, waiting to retry...\n",
      "rate limit reached, waiting to retry...\n",
      "rate limit reached, waiting to retry...\n",
      "rate limit reached, waiting to retry...\n",
      "rate limit reached, waiting to retry...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "quarter_dictionary = generate_quarters(2020, 2024)\n",
    "\n",
    "query = \"singapore industrial market outlook news\"\n",
    "# create a base DataFrame\n",
    "headers = [\"URLs\", \"Quarter\"]\n",
    "df = pd.DataFrame(columns=headers)\n",
    "\n",
    "# iterate over queries and quarters\n",
    "for quarter, time_filter in quarter_dictionary.items():\n",
    "    # perform Google search\n",
    "    results = google_search(query, num_results=100, time_filter=time_filter)\n",
    "    # append results to DataFrame\n",
    "    temp_df = pd.DataFrame({\"URLs\": results, \"Quarter\": quarter})\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "# output the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to an Excel File\n",
    "df.to_excel(\"web_scraping_urls.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2010 - 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "failed to retrieve search results: status code 429\n",
      "Empty DataFrame\n",
      "Columns: [URLs, Quarter]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "quarter_dictionary = generate_quarters(2010, 2019)\n",
    "\n",
    "query = \"singapore industrial market outlook news\"\n",
    "# create a base DataFrame\n",
    "headers = [\"URLs\", \"Quarter\"]\n",
    "new_df = pd.DataFrame(columns=headers)\n",
    "\n",
    "# iterate over queries and quarters\n",
    "for quarter, time_filter in quarter_dictionary.items():\n",
    "    # perform Google search\n",
    "    results = google_search(query, num_results=100, time_filter=time_filter)\n",
    "    # append results to DataFrame\n",
    "    temp_df = pd.DataFrame({\"URLs\": results, \"Quarter\": quarter})\n",
    "    new_df = pd.concat([new_df, temp_df], ignore_index=True)\n",
    "\n",
    "# output the DataFrame\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to an existing Excel file\n",
    "file_path = '/Users/loowenwen/Desktop/Visual Code Studio/jtc-chatgpt/web_scraping_urls.xlsx'\n",
    "existing_data = pd.read_excel(file_path)\n",
    "updated_data = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# write the updated DataFrame back to the same Excel file\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    updated_data.to_excel(writer, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
